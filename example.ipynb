{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d3a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TimeSub.estimation import cr_data, create_net_class\n",
    "from TimeSub.prediction import prediction_ability\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7957d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_breaks = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.load(\"data/covariates_TI_train.npy\")\n",
    "data = pd.read_csv(\"data/sample_TI_train.csv\")\n",
    "# cov = np.load(\"data/covariates_TV_train.npy\")\n",
    "# data = pd.read_csv(\"data/sample_TV_train.csv\")\n",
    "t_vec = data['T']\n",
    "T = data['T'].to_numpy().reshape(-1, 1)\n",
    "interval_indices = np.searchsorted(time_breaks, t_vec, side='right')-1\n",
    "Z = cov\n",
    "n = Z.shape[0]\n",
    "d = Z.shape[1]\n",
    "TX = np.zeros((n, n, d+1))\n",
    "TX[:,:,0] = T\n",
    "for i in range(d):\n",
    "    TX[:, :, i+1] = cov[:, i].reshape(1, n)\n",
    "# Z = cov[:,interval_indices,:].transpose(1, 0, 2)\n",
    "# TX = np.zeros((Z.shape[0], Z.shape[1], Z.shape[2]+1))\n",
    "# TX[:,:,0] = T\n",
    "# TX[:, :, 1:] = Z\n",
    "Delta = (data['event_type']>0).to_numpy(dtype=float).reshape(-1, 1)\n",
    "epsilon = (data['event_type']).to_numpy(dtype=float).reshape(-1, 1)\n",
    "data_train = cr_data(T,Delta,epsilon,Z,TX,cov)\n",
    "data_train.to_torch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51099ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.load(\"data/covariates_TI_test.npy\")\n",
    "data = pd.read_csv(\"data/sample_TI_test.csv\")\n",
    "# cov = np.load(\"data/covariates_TV_test.npy\")\n",
    "# data = pd.read_csv(\"data/sample_TV_test.csv\")\n",
    "t_vec = data['T']\n",
    "T = data['T'].to_numpy().reshape(-1, 1)\n",
    "interval_indices = np.searchsorted(time_breaks, t_vec, side='right')-1\n",
    "Z = cov\n",
    "n = Z.shape[0]\n",
    "d = Z.shape[1]\n",
    "TX = np.zeros((n, n, d+1))\n",
    "TX[:,:,0] = T\n",
    "for i in range(d):\n",
    "    TX[:, :, i+1] = cov[:, i].reshape(1, n)\n",
    "# Z = cov[:,interval_indices,:].transpose(1, 0, 2)\n",
    "# TX = np.zeros((Z.shape[0], Z.shape[1], Z.shape[2]+1))\n",
    "# TX[:,:,0] = T\n",
    "# TX[:, :, 1:] = Z\n",
    "Delta = (data['event_type']>0).to_numpy(dtype=float).reshape(-1, 1)\n",
    "epsilon = (data['event_type']).to_numpy(dtype=float).reshape(-1, 1)\n",
    "data_test = cr_data(T,Delta,epsilon,Z,TX,cov)\n",
    "data_test.to_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a1d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.structure_test(B_seeds = [100000+(i+1)*10 for i in range(100)],\n",
    "                          learning_rate = 1e-3, \n",
    "                          num_epoch = 300, \n",
    "                          num_epoch_ = 50, \n",
    "                          num_epoch_B = 50, \n",
    "                          learning_rate_B = 5e-2, \n",
    "                          Nets = [create_net_class(6, 12, 3)],\n",
    "                          max_batch_size = 2000 ,\n",
    "                          valid_rate = 0.5,\n",
    "                          Nets_TI = [create_net_class(5, 12, 3)],\n",
    "                          log = None,\n",
    "                          num_model = 5, \n",
    "                          num_model_B = 5):\n",
    "# Perform structure test.\n",
    "# B_seeds: list of bootstrap seeds.\n",
    "# learning_rate: learning rate for initial model training.\n",
    "# num_epoch: number of epochs for initial model training.\n",
    "# num_epoch_: number of epochs for model training during test statistic calculation.\n",
    "# num_epoch_B: number of epochs for model training during bootstrap test statistic calculation.\n",
    "# learning_rate_B: learning rate for model training during test statistic calculation.\n",
    "# Nets: list of neural network classes for the main model.\n",
    "# max_batch_size: maximum batch size for training.\n",
    "# valid_rate: proportion of data used for validation.\n",
    "# Nets_TI: list of neural network classes for the null model.\n",
    "# log: file path for logging results.\n",
    "# num_model: number of random initializations for model training during test statistic calculation.\n",
    "# num_model_B: number of random initializations for model training during bootstrap test statistic calculation\n",
    "plr,time = data_train.plr_st\n",
    "plr_B_time_list = data_train.plr_st_B\n",
    "# plt: statistic value.\n",
    "# time: time taken for the structure test.\n",
    "# plt_B_time_list: list of statistic values from bootstrap samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1f6e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.linear(num_epoch = 200, \n",
    "                  learning_rate = 0.01)\n",
    "# the original subdistribution hazard model (SHM) \n",
    "# num_epoch: number of epochs for training.\n",
    "# learning_rate: learning rate for optimization.\n",
    "data_train.spline(num_spline = 10,\n",
    "               num_epoch = 500,\n",
    "               learning_rate = 0.01)\n",
    "# the spline-based time-varying coeffcient subdistribution hazard model (TSHM) using cubic splines.\n",
    "# num_spline: number of spline basis functions.\n",
    "# num_epoch: number of epochs for training.\n",
    "# learning_rate: learning rate for optimization.\n",
    "data_train.nn_ti(Nets = [create_net_class(5, 10, 1),create_net_class(5, 20, 3)],\n",
    "            batch_num = 1,\n",
    "            learning_rate1=[1e-2,1e-3],\n",
    "            random_num = 5,\n",
    "            num_epoch = 300)\n",
    "# the nonparametric subdistribution hazard model (NSHM) using neural networks.\n",
    "# Nets: list of neural network classes to be used. \n",
    "# batch_num: number of batches for training.\n",
    "# learning_rate1: list of learning rates for different stages of training. Corresponds to Nets.\n",
    "# random_num: number of random initializations for model selection.\n",
    "# num_epoch: number of epochs for training.\n",
    "data_train.nn_tv(Nets = [create_net_class(6, 10, 1),create_net_class(6, 20, 3)],\n",
    "              batch_num = 1,\n",
    "              learning_rate1=[1e-2,1e-3],\n",
    "              random_num = 5,\n",
    "             num_epoch = 300)\n",
    "# time-varying nonparametric subdistribution hazard model (TNSHM) using neural networks.\n",
    "# Nets: list of neural network classes to be used. (6,10,1) means input size 6, hidden size 10, depth 1. \n",
    "# batch_num: number of batches for training.\n",
    "# learning_rate1: list of learning rates for different stages of training. Corresponds to Nets.\n",
    "# random_num: number of random initializations for model selection.\n",
    "# num_epoch: number of epochs for training.\n",
    "g_torch_linear =  data_train.models['linear'][0](data_test)\n",
    "g_torch_spline =  data_train.models['spline'][0](data_test)\n",
    "g_torch_nntv =  data_train.models['nn_tv'][0](data_test)\n",
    "g_torch_nnti =  data_train.models['nn_ti'][0](data_test)\n",
    "# g_torch_linear: predicted log subdistribution hazard from SHM.\n",
    "# g_torch_spline: predicted log subdistribution hazard from TSHM.\n",
    "# g_torch_nntv: predicted log subdistribution hazard from TNSHM.\n",
    "# g_torch_nnti: predicted log subdistribution hazard from NSHM.\n",
    "gc_linear,auc_linear =  prediction_ability(data_test,g_torch_linear,g0_torch=g_torch_nntv) \n",
    "gc_spline,auc_spline =  prediction_ability(data_test,g_torch_spline,g0_torch=g_torch_nntv)\n",
    "gc_nntv,auc_nntv =  prediction_ability(data_test,g_torch_nntv,g0_torch=g_torch_nntv)\n",
    "gc_nnti,auc_nnti =  prediction_ability(data_test,g_torch_nnti,g0_torch=g_torch_nntv)\n",
    "# gc_linear: GC for SHM.\n",
    "# auc_linear: AUC for SHM.\n",
    "# gc_spline: GC for TSHM.\n",
    "# auc_spline: AUC for TSHM.\n",
    "# gc_nntv: GC for TNSHM.\n",
    "# auc_nntv: AUC for TNSHM.\n",
    "# gc_nnti: GC for NSHM.\n",
    "# auc_nnti: AUC for NSHM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9250272",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.significance_test(cov_index = 5,\n",
    "                             B_seeds,learning_rate = 1e-3, \n",
    "                             num_epoch = 300, \n",
    "                             num_epoch_ = num_B, \n",
    "                             num_epoch_B = num_B, \n",
    "                             learning_rate_B = learning_B, \n",
    "                             Nets = [create_net_class(6, 12, 3)],\n",
    "                             max_batch_size = 2000,\n",
    "                             valid_rate = 0.5,\n",
    "                             Nets_null = [create_net_class(5, 12, 3)],\n",
    "                             log = None,\n",
    "                             num_model = 5, \n",
    "                             num_model_B = 5):\n",
    "# Perform significance test for a specific covariate.\n",
    "# cov_index: index of the covariate to be tested.\n",
    "# B_seeds: list of bootstrap seeds.\n",
    "# learning_rate: learning rate for initial model training.\n",
    "# num_epoch: number of epochs for initial model training.\n",
    "# num_epoch_: number of epochs for model training during test statistic calculation.\n",
    "# num_epoch_B: number of epochs for model training during bootstrap test statistic calculation.\n",
    "# learning_rate_B: learning rate for model training during test statistic calculation.\n",
    "# Nets: list of neural network classes for the main model.\n",
    "# max_batch_size: maximum batch size for training.\n",
    "# valid_rate: proportion of data used for validation.\n",
    "# Nets_null: list of neural network classes for the null model.\n",
    "# log: file path for logging results.\n",
    "# num_model: number of random initializations for model training during test statistic calculation.\n",
    "# num_model_B: number of random initializations for model training during bootstrap test statistic calculation\n",
    "plr,time = data_train.plr_si\n",
    "plr_B_time_list = data_train.plr_si_B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
